{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing CSV without using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the csv library's reader function to reads each line in a CSV file, then manually converts the lines into a list of strings, each string split by comma by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "def load_csv(filename):\n",
    "    file = open(filename, 'r')\n",
    "    lines = reader(file)\n",
    "    dataset = list(lines)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/pima-indians-diabetes.data.csv'\n",
    "dataset = load_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset has 768 rows and 9 columns\n"
     ]
    }
   ],
   "source": [
    "print('Loaded dataset has {0} rows and {1} columns'.format(len(dataset), len(dataset[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6', '148', '72', '35', '0', '33.6', '0.627', '50', '1']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert String to Float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, input CSV files for machine learning contain numeric values. We want to convert numeric values from their string representation in the CSV into their respective numeric type before we perform any other data processing. For this, we'll need a helper function to convert strings into float.\n",
    "\n",
    "We'll also write a better version of load_csv() which uses 'with open()' to open and read the csv file and takes blank intermediate lines into consideration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(filename):\n",
    "    dataset = list()\n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        \n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            \n",
    "            dataset.append(row)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_col_to_float(dataset, col):\n",
    "    for row in dataset:\n",
    "        row[col] = float(row[col].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/pima-indians-diabetes.data.csv'\n",
    "dataset = load_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0, 1.0]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in range(len(dataset[0])):\n",
    "    convert_col_to_float(dataset, col)\n",
    "\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert columns to categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical data are classifications, as in the classifications of flowers in the Iris Dataset. We can represent categorical strings into numeric categories by assigning a number for each unique category, such as the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Category          Number\n",
    "Iris-setosa       0\n",
    "Iris-virginica    1\n",
    "...               ...\n",
    "...               ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['5.1', '3.5', '1.4', '0.2', 'Iris-setosa'],\n",
       " ['4.9', '3.0', '1.4', '0.2', 'Iris-setosa'],\n",
       " ['4.7', '3.2', '1.3', '0.2', 'Iris-setosa'],\n",
       " ['4.6', '3.1', '1.5', '0.2', 'Iris-setosa'],\n",
       " ['5.0', '3.6', '1.4', '0.2', 'Iris-setosa']]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'iris.data'\n",
    "dataset = load_csv('data/iris.data')\n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_col_to_categorical(dataset, col):\n",
    "    raw_cat_data = [row[col] for row in dataset]\n",
    "    \n",
    "    # set() removes the duplicates in the column, which leaves only the unique categories\n",
    "    unique_cats = set(raw_cat_data)\n",
    "    \n",
    "    # a dictionary will map the string category to a unique number\n",
    "    lookup = dict()\n",
    "    \n",
    "    for i, unique in enumerate(unique_cats):\n",
    "        lookup[unique] = i\n",
    "        \n",
    "    for row in dataset:\n",
    "        row[col] = lookup[row[col]]\n",
    "        \n",
    "    return lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5.1, 3.5, 1.4, 0.2, 'Iris-setosa'],\n",
       " [4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n",
       " [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       " [4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n",
       " [5.0, 3.6, 1.4, 0.2, 'Iris-setosa']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert first 4 columns to float\n",
    "for col in range(4):\n",
    "    convert_col_to_float(dataset, col)\n",
    "    \n",
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1, 3.5, 1.4, 0.2, 1], [4.9, 3.0, 1.4, 0.2, 1], [4.7, 3.2, 1.3, 0.2, 1], [4.6, 3.1, 1.5, 0.2, 1], [5.0, 3.6, 1.4, 0.2, 1]]\n"
     ]
    }
   ],
   "source": [
    "# Convert the 5th column into categorcal\n",
    "lookup = convert_col_to_categorical(dataset, 4)\n",
    "\n",
    "print(dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
